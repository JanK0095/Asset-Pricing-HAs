{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JEM092 Asset Pricing - Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 82780095"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petr Dvořáček, Jan Kubal, Matyáš Mattanelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the necessary libraries\n",
    "suppressPackageStartupMessages({\n",
    "    library(quantmod) #getSymbols function\n",
    "    library(rvest) #Web scraping\n",
    "    library(stringr) #Regular expressions\n",
    "    library(xts) #Managing xts objects\n",
    "    library(V8) #Evaluating html variables\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the assigned csv file\n",
    "tickers_to_download <- read.csv(\"data_HW1/82780095_data_download.csv\")\n",
    "no_of_tickers <- nrow(tickers_to_download) #Storing the number of tickers for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted close price and Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Downloading the data from Yahoo Finance (runtime 2m 44s)\n",
    "yahoo_data_list <- vector(\"list\", no_of_tickers) #Initializing an empty list for the data\n",
    "options(\"getSymbols.warning4.0\"=FALSE) #Command to prevent an annoying message from appearing\n",
    "for (i in 1:no_of_tickers) { #Looping through the tickers\n",
    "    yahoo_data_list[[i]] <- getSymbols(tickers_to_download[i, 2], src=\"yahoo\", auto.assign = F, from = \"2007-01-01\", to = \"2022-03-01\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Volume in the 5th column: 250\n",
      "[1] Adjusted Close Price in the 6th column: 250\n"
     ]
    }
   ],
   "source": [
    "#Checking that we have adjusted close price and volume in appropriate columns for each ticker\n",
    "check_col_name <- function(ticker_data, pattern, column_no) { #Defining a function to check if a column name matches a pattern\n",
    "    ifelse(strsplit(names(ticker_data)[column_no], \"\\\\.\")[[1]][2] == pattern, return(T), return(F)) \n",
    "}\n",
    "#Applying the function on all tickers for both Volume and Adjusted price\n",
    "print(paste(\"Volume in the 5th column: \", sum(unlist(lapply(yahoo_data_list, check_col_name, pattern = \"Volume\", column_no = 5))), sep = \"\"), quote = F)\n",
    "print(paste(\"Adjusted Close Price in the 6th column: \", sum(unlist(lapply(yahoo_data_list, check_col_name, pattern = \"Adjusted\", column_no = 6))), sep = \"\"), quote = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging the available data into a single xts object\n",
    "merged_yahoo_data <- merge.xts(yahoo_data_list[[1]][, 5:6], yahoo_data_list[[2]][, 5:6]) #Initial merge, adjusted close price and volume are in the 5th and 6th columns, respectively\n",
    "for (iter in 3:no_of_tickers) { #Loop through the rest of the tickers and append each to the merged object\n",
    "    merged_yahoo_data <- merge.xts(merged_yahoo_data, yahoo_data_list[[iter]][, 5:6])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking that the number of columns is correct\n",
    "ncol(merged_yahoo_data) == no_of_tickers * 2 #Two columns for each ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book value per share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Getting the urls (runtime 1m47s)\n",
    "urls_bv <- rep(NA, no_of_tickers) #Empty vector for the urls\n",
    "for (iter in 1:no_of_tickers) { #Loop through all the tickers\n",
    "    patt <- curlGetHeaders(paste0(\"https://www.macrotrends.net/stocks/charts/\", tickers_to_download[iter, 2]))[5] #Save the response\n",
    "    name_and_ticker <- str_extract(patt, paste0(tickers_to_download[iter, 2], \"/.*/\")) #Extract the relevant pattern from the string\n",
    "    urls_bv[iter] <- paste0(\"https://www.macrotrends.net/stocks/charts/\", name_and_ticker, \"price-book\") #Complete the url and save it\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Downloading the data (runtime 3m6s)\n",
    "bv_per_share_data <- vector(\"list\", no_of_tickers) #Empty list to store the data\n",
    "for (iter in 1:no_of_tickers) { #Loop through all tickers\n",
    "  if (tickers_to_download[iter, 2] == \"LUMN\") {\n",
    "    next #Temporarily skipping one ticker since the site does not exist\n",
    "  }\n",
    "  html_request <- read_html(urls_bv[iter]) #Sending the request\n",
    "  trs <- html_request %>% \n",
    "    html_element(\"table\") %>% #Finding the table\n",
    "    html_element(\"tbody\") %>% #FInding the body of the table\n",
    "    html_elements(\"tr\") #Finding the rows of the table\n",
    "  dates <- rep(NA, length(trs)) #Empty vector to store the dates\n",
    "  values <- rep(NA, length(trs)) #Empty vector to store the values\n",
    "  for (iter2 in 1:length(trs)) { #Looping through all the rows\n",
    "    tds <- html_elements(trs[iter2], \"td\") #Extracting the cells within each row\n",
    "    dates[iter2] <- html_text(tds)[1] #First cell is the date\n",
    "    values[iter2] <- as.numeric(gsub(\"\\\\$\",\"\",html_text(tds)[3])) #Third cell is book value per share\n",
    "  }\n",
    "  dates <- as.Date(dates) #Convert dates from string to Date format\n",
    "  xts_object <- xts(x = values, order.by = dates) #Create an xts object from the results\n",
    "  names(xts_object) <- paste0(tickers_to_download[iter, 2], \".BV_per_share\") #Name it\n",
    "  bv_per_share_data[[iter]] <-  xts_object #Store the results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging the individual ticekrs together\n",
    "bv_per_share_data_merged <- merge.xts(bv_per_share_data[[1]], bv_per_share_data[[2]]) #Initial merge\n",
    "for (iter in 3:no_of_tickers) {\n",
    "    if (iter==72) {\n",
    "        next #Temporarily skipping LUMN\n",
    "    }\n",
    "    bv_per_share_data_merged <- merge.xts(bv_per_share_data_merged, bv_per_share_data[[iter]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Market capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Downloading the data\n",
    "market_cap_data <- vector(\"list\", no_of_tickers)\n",
    "for (iter in 1:no_of_tickers) { #Looping through all tickers\n",
    "    html_request <- read_html(paste0(\"https://www.macrotrends.net/assets/php/market_cap.php?t=\", tickers_to_download[iter, 2])) #Sending a request\n",
    "    script <- html_request %>% #Extracting the relevant element and converting it to text\n",
    "        html_element(\"body\") %>%\n",
    "        html_element(\"script\") %>%\n",
    "        html_text(trim = T)\n",
    "    ctx <- v8() #The extracted text contains a variable which can be evaluated using JavaScript so we initialize an execution environment\n",
    "    ctx$eval(str_extract(script,\".*]\")) #Evaluating the text. The function inside extracts the part that is relevant for us\n",
    "    extracted_data <- ctx$get(\"chartData\") #Extracting the variable (returns a data frame)\n",
    "    xts_object <- xts(x = extracted_data[, 2], order.by = as.Date(extracted_data[, 1])) #Saving as an xts object\n",
    "    names(xts_object) <- paste0(tickers_to_download[iter,2], \".Market_Cap\") #Renaming\n",
    "    market_cap_data[[iter]] <- xts_object #Storing\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging the data\n",
    "market_cap_data_merged <- merge.xts(market_cap_data[[1]], market_cap_data[[2]]) #Initial merge\n",
    "for (iter in 3:no_of_tickers) { #Looping through all the tickers\n",
    "    market_cap_data_merged <- merge.xts(market_cap_data_merged, market_cap_data[[iter]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging adjusted prices, volume, book value per share, and market capitalization\n",
    "semifinal_dataset <- merge.xts(merged_yahoo_data, bv_per_share_data_merged, market_cap_data_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Exporting to csv\n",
    "#write.zoo(semifinal_dataset, file = \"semifinal_dataset.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Initializing an empty matrix for the data\n",
    "dates <- seq(from = as.Date(\"2007-01-01\"), to = as.Date(\"2022-02-28\"), by = \"day\") #Storing the date sequence\n",
    "df <- matrix(nrow = length(dates*no_of_tickers), ncol = 6) #Empty matrix with a row for each firm/date combination\n",
    "colnames(df) <- c(\"Firm\", \"Date\", \"Adj_Close_Price\", \"Volume\", \"Market_Cap\", \"BV_per_Share\")\n",
    "df$Firm <- rep(tickers_to_download[, 2], length(dates))\n",
    "df$Date <- rep(dates, no_of_tickers)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3d0cf9620c2714139c2dfd3eeea47218c66a8564f7612a40a1666e2c73f2581"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
