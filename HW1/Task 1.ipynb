{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JEM092 Asset Pricing - Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group 82780095"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petr Dvořáček, Jan Kubal, Matyáš Mattanelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the necessary libraries\n",
    "suppressPackageStartupMessages({\n",
    "    library(quantmod) #getSymbols function\n",
    "    library(rvest) #Web scraping\n",
    "    library(stringr) #Regular expressions\n",
    "    library(xts) #Managing xts objects\n",
    "    library(V8) #Evaluating html variables\n",
    "    library(PortfolioAnalytics) #GMVP and efficient frontier\n",
    "    library(ROI.plugin.glpk) #Portfolio optimization\n",
    "    library(ROI.plugin.quadprog) #Portfolio optimization\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the assigned csv file\n",
    "tickers_to_download <- read.csv(\"data_HW1/82780095_data_download.csv\")\n",
    "no_of_tickers <- nrow(tickers_to_download) #Storing the number of tickers for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted close price and Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Downloading the data from Yahoo Finance (runtime 3m 15s)\n",
    "yahoo_data_list <- vector(\"list\", no_of_tickers) #Initializing an empty list for the data\n",
    "options(\"getSymbols.warning4.0\"=FALSE) #Command to prevent an annoying message from appearing\n",
    "for (i in 1:no_of_tickers) { #Looping through the tickers\n",
    "    yahoo_data_list[[i]] <- getSymbols(tickers_to_download[i, 2], src=\"yahoo\", auto.assign = F, from = \"2007-01-01\", to = \"2022-03-01\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Volume in the 5th column: 250\n",
      "[1] Adjusted Close Price in the 6th column: 250\n"
     ]
    }
   ],
   "source": [
    "#Checking that we have adjusted close price and volume in appropriate columns for each ticker\n",
    "check_col_name <- function(ticker_data, pattern, column_no) { #Defining a function to check if a column name matches a pattern\n",
    "    ifelse(strsplit(names(ticker_data)[column_no], \"\\\\.\")[[1]][2] == pattern, return(T), return(F)) \n",
    "}\n",
    "#Applying the function on all tickers for both Volume and Adjusted price\n",
    "print(paste(\"Volume in the 5th column: \", sum(unlist(lapply(yahoo_data_list, check_col_name, pattern = \"Volume\", column_no = 5))), sep = \"\"), quote = F)\n",
    "print(paste(\"Adjusted Close Price in the 6th column: \", sum(unlist(lapply(yahoo_data_list, check_col_name, pattern = \"Adjusted\", column_no = 6))), sep = \"\"), quote = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging the available data into a single xts object\n",
    "merged_yahoo_data <- merge.xts(yahoo_data_list[[1]][, 5:6], yahoo_data_list[[2]][, 5:6]) #Initial merge, adjusted close price and volume are in the 5th and 6th columns, respectively\n",
    "for (iter in 3:no_of_tickers) { #Loop through the rest of the tickers and append each to the merged object\n",
    "    merged_yahoo_data <- merge.xts(merged_yahoo_data, yahoo_data_list[[iter]][, 5:6])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking that the number of columns is correct\n",
    "ncol(merged_yahoo_data) == no_of_tickers * 2 #Two columns for each ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Exporting to csv just in case\n",
    "#write.zoo(merged_yahoo_data, file = \"adjusted_and_volume.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book value per share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Getting the urls (runtime 1m47s)\n",
    "urls_bv <- rep(NA, no_of_tickers) #Empty vector for the urls\n",
    "for (iter in 1:no_of_tickers) { #Loop through all the tickers\n",
    "    patt <- curlGetHeaders(paste0(\"https://www.macrotrends.net/stocks/charts/\", tickers_to_download[iter, 2]))[5] #Save the response\n",
    "    name_and_ticker <- str_extract(patt, paste0(tickers_to_download[iter, 2], \"/.*/\")) #Extract the relevant pattern from the string\n",
    "    urls_bv[iter] <- paste0(\"https://www.macrotrends.net/stocks/charts/\", name_and_ticker, \"price-book\") #Complete the url and save it\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Downloading the data (runtime 3m6s)\n",
    "bv_per_share_data <- vector(\"list\", no_of_tickers) #Empty list to store the data\n",
    "for (iter in 1:no_of_tickers) { #Loop through all tickers\n",
    "  if (tickers_to_download[iter, 2] == \"LUMN\") {\n",
    "    next #Temporarily skipping one ticker since the site does not exist\n",
    "  }\n",
    "  html_request <- read_html(urls_bv[iter]) #Sending the request\n",
    "  trs <- html_request %>% \n",
    "    html_element(\"table\") %>% #Finding the table\n",
    "    html_element(\"tbody\") %>% #FInding the body of the table\n",
    "    html_elements(\"tr\") #Finding the rows of the table\n",
    "  dates <- rep(NA, length(trs)) #Empty vector to store the dates\n",
    "  values <- rep(NA, length(trs)) #Empty vector to store the values\n",
    "  for (iter2 in 1:length(trs)) { #Looping through all the rows\n",
    "    tds <- html_elements(trs[iter2], \"td\") #Extracting the cells within each row\n",
    "    dates[iter2] <- html_text(tds)[1] #First cell is the date\n",
    "    values[iter2] <- as.numeric(gsub(\"\\\\$\",\"\",html_text(tds)[3])) #Third cell is book value per share\n",
    "  }\n",
    "  dates <- as.Date(dates) #Convert dates from string to Date format\n",
    "  xts_object <- xts(x = values, order.by = dates) #Create an xts object from the results\n",
    "  names(xts_object) <- paste0(tickers_to_download[iter, 2], \".BV_per_share\") #Name it\n",
    "  bv_per_share_data[[iter]] <-  xts_object #Store the results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging the individual tickers together\n",
    "merged_bv_per_share_data <- merge.xts(bv_per_share_data[[1]], bv_per_share_data[[2]]) #Initial merge\n",
    "for (iter in 3:no_of_tickers) {\n",
    "    if (iter==72) {\n",
    "        next #Temporarily skipping LUMN\n",
    "    }\n",
    "    merged_bv_per_share_data <- merge.xts(merged_bv_per_share_data, bv_per_share_data[[iter]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Exporting to csv just in case\n",
    "#write.zoo(merged_bv_per_share_data, file = \"bv_per_share.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Market capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Downloading the data (runtime 1m34s)\n",
    "market_cap_data <- vector(\"list\", no_of_tickers)\n",
    "for (iter in 1:no_of_tickers) { #Looping through all tickers\n",
    "    html_request <- read_html(paste0(\"https://www.macrotrends.net/assets/php/market_cap.php?t=\", tickers_to_download[iter, 2])) #Sending a request\n",
    "    script <- html_request %>% #Extracting the relevant element and converting it to text\n",
    "        html_element(\"body\") %>%\n",
    "        html_element(\"script\") %>%\n",
    "        html_text(trim = T)\n",
    "    ctx <- v8() #The extracted text contains a variable which can be evaluated using JavaScript so we initialize an execution environment\n",
    "    ctx$eval(str_extract(script,\".*]\")) #Evaluating the text. The function inside extracts the part that is relevant for us\n",
    "    extracted_data <- ctx$get(\"chartData\") #Extracting the variable (returns a data frame)\n",
    "    xts_object <- xts(x = extracted_data[, 2], order.by = as.Date(extracted_data[, 1])) #Saving as an xts object\n",
    "    names(xts_object) <- paste0(tickers_to_download[iter,2], \".Market_Cap\") #Renaming\n",
    "    market_cap_data[[iter]] <- xts_object #Storing\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging the data\n",
    "merged_market_cap_data <- merge.xts(market_cap_data[[1]], market_cap_data[[2]]) #Initial merge\n",
    "for (iter in 3:no_of_tickers) { #Looping through all the tickers\n",
    "    merged_market_cap_data <- merge.xts(merged_market_cap_data, market_cap_data[[iter]])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Exporting to csv just in case\n",
    "#write.zoo(merged_market_cap_data, file = \"market_cap.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Merging adjusted prices, volume, book value per share, and market capitalization\n",
    "semifinal_dataset <- merge.xts(merged_yahoo_data, merged_bv_per_share_data, merged_market_cap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Exporting to csv\n",
    "write.zoo(semifinal_dataset, file = \"semifinal_dataset.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Loading the 20 tickers\n",
    "tickers_20 <- read.csv(\"data_HW1/82780095_rand_download.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Finding the row number for each ticker\n",
    "iters <- rep(NA, 20)\n",
    "for (i in 1:20) {   \n",
    "    iters[i] <- tickers_to_download[tickers_to_download[, 2] == tickers_20[i, 2], 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Getting data for the relevant tickers and adjusting it\n",
    "task2_data <- vector(\"list\", 20) #Empty list for the data\n",
    "for (i in 1:20) { #Looping through the tickers\n",
    "    task2_data[[i]] <- to.monthly(yahoo_data_list[[iters[i]]][\"2015/\"], name = tickers_20[i, 2])[, 6] #Extracting data from 2015 and later and then converting it to monthly. Keeping only the Adjusted price \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Converting to returns and merging into a single xts object\n",
    "task2_data_returns <- vector(\"list\", 20)\n",
    "for (i in 1:20) {\n",
    "    task2_data_returns[[i]] <- (task2_data[[i]] - lag(task2_data[[i]]))/lag(task2_data[[i]])\n",
    "}\n",
    "#Merging\n",
    "final_returns <- merge.xts(task2_data_returns[[1]], task2_data_returns[[2]])\n",
    "for (i in 3:20) {\n",
    "    final_returns <- merge.xts(final_returns, task2_data_returns[[i]])\n",
    "}\n",
    "names(final_returns) <- gsub(\".Adjusted\", \"\", names(final_returns)) #Renaming for conciseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Calculating the Global Minimum Variance Portfolio\n",
    "pspec <- portfolio.spec(assets = tickers_20[, 2]) #Specifying the stock names\n",
    "initial_portfolio <- add.constraint(portfolio = pspec, type = \"full_investment\") #Adding a constraint\n",
    "minvar <- add.objective(portfolio = initial_portfolio, type = \"risk\", name = \"var\") #Adding an objective\n",
    "opt_minvar <- optimize.portfolio(R = final_returns, portfolio = minvar, optimize_method = \"ROI\") #Optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't know how to resolve the error yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in seq.default(from = minret, to = maxret, length.out = n.portfolios): 'from' must be a finite number\n",
     "output_type": "error",
     "traceback": [
      "Error in seq.default(from = minret, to = maxret, length.out = n.portfolios): 'from' must be a finite number\nTraceback:\n",
      "1. create.EfficientFrontier(R = final_returns[, 1:10], portfolio = portfolioA, \n .     type = \"mean-var\")",
      "2. meanvar.efficient.frontier(portfolio = portfolio, R = R, n.portfolios = n.portfolios, \n .     risk_aversion = risk_aversion, ... = ...)",
      "3. seq(from = minret, to = maxret, length.out = n.portfolios)",
      "4. seq.default(from = minret, to = maxret, length.out = n.portfolios)",
      "5. stop(\"'from' must be a finite number\")"
     ]
    }
   ],
   "source": [
    "#Constructing portfolios A and B\n",
    "pspecA <- portfolio.spec(assets = tickers_20[1:10, 2])\n",
    "pspecB <- portfolio.spec(assets = tickers_20[11:20, 2])\n",
    "portfolioA <- add.constraint(portfolio = pspecA, type = \"box\", min = min(opt_minvar$weights[1:10]), max = 1)\n",
    "portfolioB <- add.constraint(portfolio = pspecB, type = \"box\", min = min(opt_minvar$weights[11:20]), max = 1)\n",
    "#Creating the efficient frontier\n",
    "eff_front_A <- create.EfficientFrontier(R = final_returns[, 1:10], portfolio = portfolioA, type = 'mean-var')\n",
    "eff_front_B <- create.EfficientFrontier(R = final_returns[, 10:11], portfolio = portfolioB, type = 'mean-var')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3d0cf9620c2714139c2dfd3eeea47218c66a8564f7612a40a1666e2c73f2581"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
